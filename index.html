<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Drip-statistical-learning by lakshmiDRIP</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/github-dark.css">
    <script src="javascripts/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>Drip-statistical-learning</h1>
        <p>DRIP Statistical Learning</p>
        <p class="view"><a href="https://github.com/lakshmiDRIP/DRIP-Statistical-Learning">View the Project on GitHub <small>lakshmiDRIP/DRIP-Statistical-Learning</small></a></p>
        <ul>
          <li><a href="https://github.com/lakshmiDRIP/DRIP-Statistical-Learning/zipball/master">Download <strong>ZIP File</strong></a></li>
          <li><a href="https://github.com/lakshmiDRIP/DRIP-Statistical-Learning/tarball/master">Download <strong>TAR Ball</strong></a></li>
          <li><a href="https://github.com/lakshmiDRIP/DRIP-Statistical-Learning">View On <strong>GitHub</strong></a></li>
        </ul>
      </header>
      <section>
        <p align="center"><img src="https://github.com/lakshmiDRIP/DRIP/blob/master/DRIP_Logo.gif?raw=true" width="100"></p>

<p><strong>v2.63</strong>  <em>1 March 2017</em></p>

<p>DRIP Statistical Learning is a collection of Java libraries for Statistical Evaluation and Machine Learning.</p>

<p>DRIP Statistical Learning is composed of the following main libraries:</p>

<ul>
<li>Probabilistic Sequence Measure Concentration Bounds Library</li>
<li>Statistical Learning Theory Framework Library</li>
<li>Empirical Risk Minimization Library</li>
<li>VC and Capacity Measure Library</li>
<li>Covering Numbers Library</li>
<li>Alternate Statistical Learning Library</li>
<li>Problem Space and Algorithms Families Library</li>
<li>Parametric Classification Library</li>
<li>Non-parametric Classification Library</li>
<li>Clustering Library</li>
<li>Ensemble Learning Library</li>
<li>Multi-linear Sub-space Learning Library</li>
<li>Real-Valued Sequence Learning Library</li>
<li>Real-Valued Learning Library</li>
<li>Sequence Labeling Library</li>
<li>Bayesian Library</li>
<li>Linear Algebra Support Library</li>
</ul>

<p>For Installation, Documentation and Samples, and the associated supporting Numerical Libraries please check out <a href="https://github.com/lakshmiDRIP/DRIP">DRIP</a>.</p>

<h2>
<a id="drip-core-technical-specifications" class="anchor" href="#drip-core-technical-specifications" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>DRIP Core Technical Specifications</h2>

<ul>
<li><a href="https://github.com/lakshmiDRIP/DRIP/tree/master/Docs/DRIPSpecification/AssetAllocation/AssetAllocation_v2.56.pdf">Asset Allocation Library</a></li>
<li><a href="https://github.com/lakshmiDRIP/DRIP/tree/master/Docs/DRIPSpecification/FixedIncome/FixedIncomeAnalytics_v2.58.pdf">Fixed Income Analytics</a></li>
<li><a href="https://github.com/lakshmiDRIP/DRIP/tree/master/Docs/DRIPSpecification/TransactionCost/TransactionCostAnalytics_v2.57.pdf">Transaction Cost Analytics</a></li>
<li><a href="https://github.com/lakshmiDRIP/DRIP/tree/master/Docs/DRIPSpecification/XVA/XVAAnalytics_v2.62.pdf">XVA Analytics</a></li>
</ul>

<h2>
<a id="drip-supporting-technical-specifications" class="anchor" href="#drip-supporting-technical-specifications" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>DRIP Supporting Technical Specifications</h2>

<ul>
<li><a href="https://github.com/lakshmiDRIP/DRIP/tree/master/Docs/DRIPSpecification/SplineBuilder/SplineBuilder_v0.82.pdf">Spline Builder Library</a></li>
<li><a href="https://github.com/lakshmiDRIP/DRIP/tree/master/Docs/DRIPSpecification/NumericalOptimizer/NumericalOptimization_v2.05.pdf">Numerical Optimization Library</a></li>
<li><a href="https://github.com/lakshmiDRIP/DRIP/tree/master/Docs/DRIPSpecification/StatisticalLearning/StatisticalLearningLibrary_v0.80.pdf">Statistical Learning Library</a></li>
<li><a href="https://github.com/lakshmiDRIP/DRIP/tree/master/Docs/DRIPSpecification/MachineLearning/MachineLearningLibrary_v0.92.pdf">Machine Learning Library</a></li>
</ul>

<h2>
<a id="additional-documentation" class="anchor" href="#additional-documentation" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Additional Documentation</h2>

<ul>
<li><a href="https://github.com/lakshmiDRIP/DRIP">DRIP GitHub Source</a></li>
<li><a href="https://lakshmidrip.github.io/DRIP/Javadoc/index.html">DRIP API Javadoc</a></li>
<li><a href="https://github.com/lakshmiDRIP/DRIP/tree/master/ReleaseNotes">DRIP Release Notes</a></li>
<li><a href="https://github.com/lakshmiDRIP/DRIP/tree/master/Docs/DRIPSpecification">DRIP Technical Specifications</a></li>
<li><a href="https://github.com/lakshmiDRIP/DRIP/tree/master/Docs/External">DRIP External Specifications</a></li>
<li>User guide is a work in progress!</li>
</ul>

<h2>
<a id="samples-statistical-learning---need-much-much-more" class="anchor" href="#samples-statistical-learning---need-much-much-more" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Samples (Statistical Learning - Need much, much more!)</h2>

<ul>
<li><a href="https://github.com/lakshmiDRIP/DRIP/tree/master/org/drip/sample/efronstein">Efron Stein Bounds</a></li>
<li><a href="https://github.com/lakshmiDRIP/DRIP/tree/master/org/drip/sample/sequence">Custom Sequence Bounds</a></li>
<li><a href="https://github.com/lakshmiDRIP/DRIP/tree/master/org/drip/sample/coveringnumber">Covering Number Bounds</a></li>
<li><a href="https://github.com/lakshmiDRIP/DRIP/tree/master/org/drip/sample/classifier">Binary Classifier Bounds</a></li>
</ul>

<h2>
<a id="samples-numerical-support---need-much-more" class="anchor" href="#samples-numerical-support---need-much-more" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Samples (Numerical Support - Need much more!)</h2>

<ul>
<li><a href="https://github.com/lakshmiDRIP/DRIP/tree/master/org/drip/sample/matrix">Linear Algebra/Components</a></li>
<li><a href="https://github.com/lakshmiDRIP/DRIP/tree/master/org/drip/sample/measure">Closed Distribution Measure</a></li>
<li><a href="https://github.com/lakshmiDRIP/DRIP/tree/master/org/drip/sample/statistics">Empirical Distribution Measure</a></li>
<li><a href="https://github.com/lakshmiDRIP/DRIP/tree/master/org/drip/sample/numerical">Search/Quadrature/Fourier</a></li>
<li><a href="https://github.com/lakshmiDRIP/DRIP/tree/master/org/drip/sample/numeraire">Correlated Joint Univariate Random Evolution</a></li>
</ul>

<h2>
<a id="features" class="anchor" href="#features" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Features</h2>

<h3>
<a id="probabilistic-bounds-and-concentration-of-measure-sequences" class="anchor" href="#probabilistic-bounds-and-concentration-of-measure-sequences" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Probabilistic Bounds and Concentration of Measure Sequences</h3>

<h4>
<a id="probabilistic-bounds" class="anchor" href="#probabilistic-bounds" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Probabilistic Bounds</h4>

<ul>
<li>Tail Probability Bounds Estimation</li>
<li>Basic Probability Inequalities</li>
<li>Cauchy-Schwartz Inequality</li>
<li>Association Inequalities</li>
<li>Moment, Gaussian, and Exponential Bounds</li>
<li>Bounding Sums of Independent Random Variables</li>
<li>Non Moment Based Bounding - Hoeffding Bound</li>
<li>Moment Based Bounds</li>
<li>Binomial Tails</li>
<li>Custom Bounds for Special i.i.d. Sequences</li>
</ul>

<h4>
<a id="efron-stein-bounds" class="anchor" href="#efron-stein-bounds" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Efron Stein Bounds</h4>

<ul>
<li>Martingale Differences Sum Inequality</li>
<li>Efron-Stein Inequality</li>
<li>Bounded Differences Inequality</li>
<li>Bounded Differences Inequality - Applications</li>
<li>Self-Bounding Functions</li>
<li>Configuration Functions</li>
</ul>

<h4>
<a id="entropy-methods" class="anchor" href="#entropy-methods" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Entropy Methods</h4>

<ul>
<li>Information Theory - Basics</li>
<li>Tensorization of the Entropy</li>
<li>Logarithmic Sobolev Inequalities</li>
<li>Logarithmic Sobolev Inequalities - Applications</li>
<li>Exponential Inequalities for Self-Bounding Functions</li>
<li>Combinatorial Entropy</li>
<li>Variations on the Theme of Self-Bounding Functions</li>
</ul>

<h4>
<a id="concentration-of-measure" class="anchor" href="#concentration-of-measure" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Concentration of Measure</h4>

<ul>
<li>Equivalent Bounded Differences Inequality</li>
<li>Convex Distance Inequality</li>
<li>Convex Distance Inequality - Proof</li>
<li>Application of the Convex Distance Inequality - Bin Packing</li>
</ul>

<h3>
<a id="statistical-learning-theory---foundation-and-framework" class="anchor" href="#statistical-learning-theory---foundation-and-framework" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Statistical Learning Theory - Foundation and Framework</h3>

<h4>
<a id="standard-slt-framework" class="anchor" href="#standard-slt-framework" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Standard SLT Framework</h4>

<ul>
<li>Computational Learning Theory</li>
<li>Probably Approximately Correct (PAC) Learning</li>
<li>PAC Definitions and Terminology</li>
<li>SLT Setup</li>
<li>Algorithms for Reducing Over-fitting</li>
<li>Bayesian Normalized Regularizer Setup</li>
</ul>

<h4>
<a id="generalization-and-consistency" class="anchor" href="#generalization-and-consistency" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Generalization and Consistency</h4>

<ul>
<li>Types of Consistency</li>
<li>Bias-Variance or Estimation-Approximation Trade-off</li>
<li>Bias-Variance Decomposition</li>
<li>Bias-Variance Optimization</li>
<li>Generalization and Consistency for kNN</li>
</ul>

<h3>
<a id="empirical-risk-minimization---principles-and-techniques" class="anchor" href="#empirical-risk-minimization---principles-and-techniques" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Empirical Risk Minimization - Principles and Techniques</h3>

<h4>
<a id="empirical-risk-minimization" class="anchor" href="#empirical-risk-minimization" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Empirical Risk Minimization</h4>

<ul>
<li>Overview</li>
<li>The Loss Functions and Empirical Risk Minimization Principles</li>
<li>Application of the Central Limit Theorem (CLT) and the Law of Large Numbers (LLN)</li>
<li>Inconsistency of Empirical Risk Minimizers</li>
<li>Uniform Convergence</li>
<li>ERM Complexity</li>
</ul>

<h4>
<a id="symmetrization" class="anchor" href="#symmetrization" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Symmetrization</h4>

<ul>
<li>The Symmetrization Lemma</li>
</ul>

<h4>
<a id="generalization-bounds" class="anchor" href="#generalization-bounds" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Generalization Bounds</h4>

<ul>
<li>The Union Bound</li>
<li>Shattering Coefficient</li>
<li>Empirical Risk Generalization Bound</li>
<li>Large Margin Bounds</li>
</ul>

<h4>
<a id="rademacher-complexity" class="anchor" href="#rademacher-complexity" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Rademacher Complexity</h4>

<ul>
<li>Rademacher-based Uniform Convergence</li>
<li>VC Entropy</li>
<li>Chaining Technique</li>
</ul>

<h4>
<a id="local-rademacher-averages" class="anchor" href="#local-rademacher-averages" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Local Rademacher Averages</h4>

<ul>
<li>Star-Hull and Sub-Root Functions</li>
<li>Local Rademacher Averages and Fixed Point</li>
<li>Local Rademacher Averages - Consequences</li>
</ul>

<h4>
<a id="normalized-erm" class="anchor" href="#normalized-erm" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Normalized ERM</h4>

<ul>
<li>Computing the Normalized Empirical Risk Bounds</li>
<li>De-normalized Bounds</li>
</ul>

<h4>
<a id="noise-conditions" class="anchor" href="#noise-conditions" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Noise Conditions</h4>

<ul>
<li>SLT Analysis Metrics</li>
<li>Types of Noise Conditions</li>
<li>Relative Loss Class</li>
</ul>

<h3>
<a id="vc-theory-and-capacity-measure-analysis" class="anchor" href="#vc-theory-and-capacity-measure-analysis" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>VC Theory and Capacity Measure Analysis</h3>

<h4>
<a id="vc-theory-and-vc-dimension" class="anchor" href="#vc-theory-and-vc-dimension" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>VC Theory and VC Dimension</h4>

<ul>
<li>Empirical Processes</li>
<li>Bounding the Empirical Loss Function</li>
<li>VC Dimension - Setup</li>
<li>Incorporating the Formal VC Definition</li>
<li>VC Dimension Examples</li>
<li>VC Dimension vs. Popper's Dimension</li>
</ul>

<h4>
<a id="sauer-lemma-and-vc-classifier-framework" class="anchor" href="#sauer-lemma-and-vc-classifier-framework" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Sauer Lemma and VC Classifier Framework</h4>

<ul>
<li>Working out Sauer Lemma Bounds</li>
<li>Sauer Lemma ERM Bounds</li>
<li>VC Index</li>
<li>VC Classifier Framework</li>
</ul>

<h3>
<a id="capacitycomplexity-estimation-using-covering-numbers" class="anchor" href="#capacitycomplexity-estimation-using-covering-numbers" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Capacity/Complexity Estimation Using Covering Numbers</h3>

<h4>
<a id="covering-and-entropy-numbers" class="anchor" href="#covering-and-entropy-numbers" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Covering and Entropy Numbers</h4>

<ul>
<li>Nomenclature- Normed Spaces</li>
<li>Covering, Entropy, and Dyadic Numbers</li>
<li>Background and Overview of Basic Results</li>
</ul>

<h4>
<a id="covering-numbers-for-real-valued-function-classes" class="anchor" href="#covering-numbers-for-real-valued-function-classes" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Covering Numbers for Real-Valued Function Classes</h4>

<ul>
<li>Functions of Bounded Variation</li>
<li>Functions of Bounded Variation - Upper Bound</li>
<li>Functions of Bounded Variation - Lower Bound</li>
<li>General Function Classes</li>
<li>General Function Class Bounds</li>
<li>General Function Class Bounds - Lemmas</li>
<li>General Function Class - Upper Bounds</li>
<li>General Function Class - Lower Bounds</li>
</ul>

<h4>
<a id="operator-theory-methods-for-entropy-numbers" class="anchor" href="#operator-theory-methods-for-entropy-numbers" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Operator Theory Methods for Entropy Numbers</h4>

<ul>
<li>Generalization Bounds via Uniform Convergence</li>
<li>Basic Uniform Convergence Bounds</li>
<li>Loss Function Induced Classes</li>
<li>Standard Form of Uniform Convergence</li>
</ul>

<h4>
<a id="kernel-machines" class="anchor" href="#kernel-machines" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Kernel Machines</h4>

<ul>
<li>SVM Capacity Control</li>
<li>Nonlinear Kernels</li>
<li>Generalization Performance of Regularization Networks</li>
<li>Covering Number Determination Steps</li>
<li>Challenges Presenting Master Generalization Error</li>
</ul>

<h4>
<a id="entropy-number-for-kernel-machines" class="anchor" href="#entropy-number-for-kernel-machines" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Entropy Number for Kernel Machines</h4>

<ul>
<li>Mercer Kernels</li>
<li>Equivalent Kernels</li>
<li>Mapping Phi into L2</li>
<li>Corrigenda to the Mercer Conditions</li>
<li>L2 Unit Ball -&gt; Epsilon Mapping Scaling Operator</li>
<li>Unit Bounding Operator Entropy Numbers</li>
<li>The SVM Operator</li>
<li>Maurey's Theorem</li>
<li>Bounds for SV Classes</li>
<li>Asymptotic Rates of Decay for the Entropy Numbers</li>
</ul>

<h4>
<a id="discrete-spectra-of-convolution-operators" class="anchor" href="#discrete-spectra-of-convolution-operators" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Discrete Spectra of Convolution Operators</h4>

<ul>
<li>Kernels with Compact/Non-compact Support</li>
<li>The Kernel Operator Eigenvalues</li>
<li>Choosing Nu</li>
<li>Extensions to d-dimensions</li>
</ul>

<h4>
<a id="covering-numbers-for-given-decay-rates" class="anchor" href="#covering-numbers-for-given-decay-rates" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Covering Numbers for Given Decay Rates</h4>

<ul>
<li>Asymptotic/Non-asymptotic Decay of Covering Numbers</li>
<li>Polynomial Eigenvalue Decay</li>
<li>Summation and Integration of Non-decreasing Functions</li>
<li>Exponential Polynomial Decay</li>
</ul>

<h4>
<a id="kernels-for-high-dimensional-data" class="anchor" href="#kernels-for-high-dimensional-data" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Kernels for High-Dimensional Data</h4>

<ul>
<li>Kernel Fourier Transforms</li>
<li>Degenerate Kernel Bounds</li>
<li>Covering Numbers for Degenerate Systems</li>
<li>Bounds for Kernels in R^d</li>
<li>Impact of the Fourier Transform Decay on the Entropy Numbers</li>
</ul>

<h4>
<a id="regularization-networks-entropy-numbers-determination---practice" class="anchor" href="#regularization-networks-entropy-numbers-determination---practice" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Regularization Networks Entropy Numbers Determination - Practice</h4>

<ul>
<li>Custom Applications of the Kernel Machines Entropy Numbers</li>
<li>Extensions to the Operator-Theoretic Viewpoint for Covering Numbers</li>
</ul>

<h3>
<a id="alternate-statistical-learning-approaches" class="anchor" href="#alternate-statistical-learning-approaches" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Alternate Statistical Learning Approaches</h3>

<h4>
<a id="minimum-description-length-approach" class="anchor" href="#minimum-description-length-approach" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Minimum Description Length Approach</h4>

<ul>
<li>Coding Approaches</li>
<li>MDL Analyses</li>
</ul>

<h4>
<a id="bayesian-methods" class="anchor" href="#bayesian-methods" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Bayesian Methods</h4>

<ul>
<li>Bayesian and Frequentist Approaches</li>
<li>Bayesian Approaches</li>
</ul>

<h4>
<a id="knowledge-based-bounds" class="anchor" href="#knowledge-based-bounds" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Knowledge Based Bounds</h4>

<ul>
<li>Places to Incorporate Bounds</li>
<li>Prior Knowledge into the Function Space</li>
</ul>

<h4>
<a id="approximation-error-and-bayes-consistency" class="anchor" href="#approximation-error-and-bayes-consistency" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Approximation Error and Bayes' Consistency</h4>

<ul>
<li>Nested Function Spaces</li>
<li>Regularization</li>
<li>Achieving Zero Approximation Error</li>
<li>Rate of Convergence</li>
</ul>

<h4>
<a id="no-free-lunch-theorem" class="anchor" href="#no-free-lunch-theorem" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>No Free Lunch Theorem</h4>

<ul>
<li>Algorithmic Consistency</li>
<li>NFT Formal Statements</li>
</ul>

<h3>
<a id="problem-space-and-algorthm-families" class="anchor" href="#problem-space-and-algorthm-families" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Problem Space and Algorthm Families</h3>

<h4>
<a id="generative-and-discriminative-models" class="anchor" href="#generative-and-discriminative-models" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Generative and Discriminative Models</h4>

<ul>
<li>Generative Models</li>
<li>Discriminant Models</li>
<li>Examples of Discriminant Approaches</li>
<li>Differences between Generative and Discriminant Models</li>
</ul>

<h4>
<a id="supervised-learning" class="anchor" href="#supervised-learning" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Supervised Learning</h4>

<ul>
<li>Supervised Learning Practice Steps</li>
<li>Challenges with Supervised Learning Practice</li>
<li>Formulation</li>
</ul>

<h4>
<a id="unsupervised-learning" class="anchor" href="#unsupervised-learning" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Unsupervised Learning</h4>

<h4>
<a id="machine-learning" class="anchor" href="#machine-learning" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Machine Learning</h4>

<ul>
<li>Calibration vs. Learning</li>
</ul>

<h4>
<a id="pattern-recognition" class="anchor" href="#pattern-recognition" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Pattern Recognition</h4>

<ul>
<li>Supervised vs. Unsupervised Pattern Recognition</li>
<li>Probabilistic Pattern Recognition</li>
<li>Formulation of Pattern Recognition</li>
<li>Pattern Recognition Practice SKU</li>
<li>Pattern Recognition Applications</li>
</ul>

<h3>
<a id="parametric-classification-algorithms" class="anchor" href="#parametric-classification-algorithms" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Parametric Classification Algorithms</h3>

<h4>
<a id="statistical-classification" class="anchor" href="#statistical-classification" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Statistical Classification</h4>

<h4>
<a id="linear-discriminant-analysis" class="anchor" href="#linear-discriminant-analysis" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Linear Discriminant Analysis</h4>

<ul>
<li>Setup and Formulation</li>
<li>Fischer's Linear Discriminant</li>
<li>Quadratic Discriminant Analysis</li>
</ul>

<h4>
<a id="logistic-regression" class="anchor" href="#logistic-regression" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Logistic Regression</h4>

<ul>
<li>Formulation</li>
<li>Goodness of Fit</li>
<li>Mathematical Setup</li>
<li>Bayesian Logistic Regression</li>
<li>Logistic Regression Extensions</li>
<li>Model Suitability Tests with Cross Validation</li>
</ul>

<h4>
<a id="multinomial-logistic-regression" class="anchor" href="#multinomial-logistic-regression" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Multinomial Logistic Regression</h4>

<ul>
<li>Setup and Formulation</li>
</ul>

<h3>
<a id="non-parametric-classification-algorithms" class="anchor" href="#non-parametric-classification-algorithms" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Non-Parametric Classification Algorithms</h3>

<h4>
<a id="decision-trees-and-decision-lists" class="anchor" href="#decision-trees-and-decision-lists" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Decision Trees and Decision Lists</h4>

<h4>
<a id="variable-bandwidth-kernel-density-estimation" class="anchor" href="#variable-bandwidth-kernel-density-estimation" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Variable Bandwidth Kernel Density Estimation</h4>

<h4>
<a id="k-nearest-neighbors-algorithm" class="anchor" href="#k-nearest-neighbors-algorithm" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>k Nearest Neighbors Algorithm</h4>

<h4>
<a id="perceptron" class="anchor" href="#perceptron" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Perceptron</h4>

<h4>
<a id="support-vector-machines-svm" class="anchor" href="#support-vector-machines-svm" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Support Vector Machines (SVM)</h4>

<h4>
<a id="gene-expression-programming-gep" class="anchor" href="#gene-expression-programming-gep" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Gene Expression Programming (GEP)</h4>

<h3>
<a id="clustering-algorithms" class="anchor" href="#clustering-algorithms" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Clustering Algorithms</h3>

<h4>
<a id="cluster-analysis" class="anchor" href="#cluster-analysis" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Cluster Analysis</h4>

<ul>
<li>Cluster Models</li>
<li>Connectivity Based Clustering</li>
<li>Centroid Based Clustering</li>
<li>Distribution Based Clustering</li>
<li>Density Based Clustering</li>
<li>Clustering Enhancements</li>
<li>Internal Cluster Evaluation</li>
<li>External Cluster Evaluation</li>
<li>Clustering Axiom</li>
</ul>

<h4>
<a id="mixture-model" class="anchor" href="#mixture-model" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Mixture Model</h4>

<ul>
<li>Generic Mixture Model Details</li>
<li>Specific Mixture Models</li>
<li>Mixture Model Samples</li>
<li>Identifiability</li>
<li>Expectation Maximization</li>
<li>Alternatives to Expectation Maximization</li>
<li>Mixture Model Extensions</li>
</ul>

<h4>
<a id="deep-learning" class="anchor" href="#deep-learning" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Deep Learning</h4>

<ul>
<li>Unsupervised Representation Learner</li>
<li>Deep Learning using ANN</li>
<li>Deep Learning Architectures</li>
<li>Challenges with the DNN Approach</li>
<li>Deep Belief Networks (DBN)</li>
<li>Convolutional Neural Networks (CNN)</li>
<li>Deep Learning Evaluation Data Sets</li>
<li>Neurological Basis of Deep Learning</li>
</ul>

<h4>
<a id="hierarchical-clustering" class="anchor" href="#hierarchical-clustering" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Hierarchical Clustering</h4>

<h4>
<a id="k-means-clustering" class="anchor" href="#k-means-clustering" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>k-Means Clustering</h4>

<ul>
<li>Mathematical Formulation</li>
<li>The Standard Algorithm</li>
<li>k-Means Initialization Schemes</li>
<li>k-Means Complexity</li>
<li>k-Means Variations</li>
<li>k-Means Applications</li>
<li>Alternate k-Means Formulations</li>
</ul>

<h4>
<a id="correlation-clustering" class="anchor" href="#correlation-clustering" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Correlation Clustering</h4>

<h4>
<a id="kernel-principal-component-analysis-kernel-pca" class="anchor" href="#kernel-principal-component-analysis-kernel-pca" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Kernel Principal Component Analysis (Kernel PCA)</h4>

<h3>
<a id="ensemble-learning-algorithms" class="anchor" href="#ensemble-learning-algorithms" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Ensemble Learning Algorithms</h3>

<h4>
<a id="ensemble-learning" class="anchor" href="#ensemble-learning" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Ensemble Learning</h4>

<ul>
<li>Overview</li>
<li>Theoretical Underpinnings</li>
<li>Ensemble Aggregator Types</li>
<li>Bayes' Optimal Classifier</li>
<li>Bagging and Boosting</li>
<li>Bayesian Model Averaging (BMA)</li>
<li>Baysian Model Combination (BMC)</li>
<li>Bucket of Models (BOM)</li>
<li>Stacking</li>
<li>Ensemble Averaging vs. Basis Spline Representation</li>
</ul>

<h4>
<a id="ann-ensemble-averaging" class="anchor" href="#ann-ensemble-averaging" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>ANN Ensemble Averaging</h4>

<ul>
<li>Techniques and Results</li>
</ul>

<h4>
<a id="boosting" class="anchor" href="#boosting" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Boosting</h4>

<ul>
<li>Philosophy behind Boosting Algorithms</li>
<li>Popular Boosting Algorithms and Drawbacks</li>
</ul>

<h4>
<a id="bootstrap-averaging" class="anchor" href="#bootstrap-averaging" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Bootstrap Averaging</h4>

<ul>
<li>Sample Generation</li>
<li>Bagging with 1NN - Theoretical Treatment</li>
</ul>

<h3>
<a id="multi-linear-sub-space-learning-algorithms" class="anchor" href="#multi-linear-sub-space-learning-algorithms" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Multi-linear Sub-space Learning Algorithms</h3>

<h4>
<a id="tensors-and-multi-linear-sub-space-algorithms" class="anchor" href="#tensors-and-multi-linear-sub-space-algorithms" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Tensors and Multi-linear Sub-space Algorithms</h4>

<ul>
<li>Tensors</li>
<li>Multi-linear Sub-space Learning</li>
<li>Multi-linear PCA</li>
</ul>

<h3>
<a id="real-valued-sequence-learning-algorithms" class="anchor" href="#real-valued-sequence-learning-algorithms" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Real-Valued Sequence Learning Algorithms</h3>

<h4>
<a id="kalman-filtering" class="anchor" href="#kalman-filtering" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Kalman Filtering</h4>

<ul>
<li>Continuous Time Kalman Filtering</li>
<li>Nonlinear Kalman Filtering</li>
<li>Kalman Smoothing</li>
</ul>

<h4>
<a id="particle-filtering" class="anchor" href="#particle-filtering" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Particle Filtering</h4>

<h3>
<a id="real-valued-learning-algorithms" class="anchor" href="#real-valued-learning-algorithms" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Real-Valued Learning Algorithms</h3>

<h4>
<a id="regression-analysis" class="anchor" href="#regression-analysis" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Regression Analysis</h4>

<ul>
<li>Linear Regression</li>
<li>Assumptions Underlying Basis Linear Regression</li>
<li>Multi-variate Regression Analysis</li>
<li>Multi-variate Predictor/Response Regression</li>
<li>OLS on Basis Spline Representation</li>
<li>OLS on Basis Spline Representation with Roughness Penalty</li>
<li>Linear Regression Estimator Extensions</li>
<li>Bayesian Approach to Regression Analysis</li>
</ul>

<h4>
<a id="component-analysis" class="anchor" href="#component-analysis" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Component Analysis</h4>

<ul>
<li>Independent Component Analysis (ICA) Specification</li>
<li>Independent Component Analysis (ICA) Formulation</li>
<li>Principal Component Analysis</li>
<li>Principal COmponent Analysis - Constrained Formulation</li>
<li>2D Principal Component Analysis - Constrained Formulation</li>
<li>2D Principal Component Analysis - Lagrange Multiplier Based Constrained Formulation</li>
<li>nD Principal Component Analysis - Lagrange Multiplier Based Constrained Formulation</li>
<li>Information Theoretic Analysis of PCA</li>
<li>Empirical PCA Estimation From Data Set</li>
</ul>

<h3>
<a id="sequence-label-learning-algorithms" class="anchor" href="#sequence-label-learning-algorithms" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Sequence Label Learning Algorithms</h3>

<h4>
<a id="hidden-markov-models" class="anchor" href="#hidden-markov-models" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Hidden Markov Models</h4>

<ul>
<li>HMM State Transition/Emission Parameter Estimation</li>
<li>HMM Based Inference</li>
<li>Non-Bayesian HMM Model Setup</li>
<li>Bayesian Extension to the HMM Model Setup</li>
<li>HMM in Practical World</li>
</ul>

<h4>
<a id="markov-chain-models" class="anchor" href="#markov-chain-models" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Markov Chain Models</h4>

<ul>
<li>Markov Property</li>
<li>Markov Chains</li>
<li>Classification of the Markov Models</li>
<li>Monte Carlo Markov Chains (MCMC)</li>
<li>MCMC for Multi-dimensional Integrals</li>
</ul>

<h4>
<a id="markov-random-and-conditional-fields" class="anchor" href="#markov-random-and-conditional-fields" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Markov Random and Conditional Fields</h4>

<ul>
<li>MRF/CRF Axiomatic Properties/Definitions</li>
<li>Clique Factorization</li>
<li>Inference in MRF/CRF</li>
</ul>

<h4>
<a id="maximum-entropy-markov-models" class="anchor" href="#maximum-entropy-markov-models" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Maximum Entropy Markov Models</h4>

<h4>
<a id="probabilistic-grammar-and-parsing" class="anchor" href="#probabilistic-grammar-and-parsing" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Probabilistic Grammar and Parsing</h4>

<ul>
<li>Parsing</li>
<li>Parser</li>
<li>Context-Free Grammar (CFG)</li>
</ul>

<h3>
<a id="bayesian-analysis" class="anchor" href="#bayesian-analysis" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Bayesian Analysis</h3>

<h4>
<a id="concepts-formulation-usage-and-application" class="anchor" href="#concepts-formulation-usage-and-application" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Concepts, Formulation, Usage, and Application</h4>

<ul>
<li>Applicability</li>
<li>Analysis of Bayesian Systems</li>
<li>Bayesian Networks</li>
<li>Hypothesis Testing</li>
<li>Bayesian Updating</li>
<li>Maximum Entropy Techniques</li>
<li>Priors</li>
<li>Predictive Posteriors and Priors</li>
<li>Approximate Bayesian Computation</li>
<li>Measurement and Parametric Calibration</li>
<li>Bayesian Regression Analysis</li>
<li>Extensions to Bayesian Regression Analysis</li>
<li>Spline Proxying of Bayesian Systems</li>
</ul>

<h3>
<a id="linear-algebra-support" class="anchor" href="#linear-algebra-support" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Linear Algebra Support</h3>

<h4>
<a id="optimizer" class="anchor" href="#optimizer" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Optimizer</h4>

<ul>
<li>Constrained Optimization using Lagrangian</li>
<li>Least Squares Optimizer</li>
<li>Multi-variate Distribution</li>
</ul>

<h4>
<a id="linear-systems-analysis-and-transformation" class="anchor" href="#linear-systems-analysis-and-transformation" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Linear Systems Analysis and Transformation</h4>

<ul>
<li>Matrix Transforms</li>
<li>System of Linear Equations</li>
<li>Orthogonalization</li>
<li>Gaussian Elimination</li>
</ul>

<h2>
<a id="contact" class="anchor" href="#contact" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Contact</h2>

<p><a href="mailto:lakshmi@synergicdesign.com">lakshmi@synergicdesign.com</a></p>
      </section>
    </div>
    <footer>
      <p>Project maintained by <a href="https://github.com/lakshmiDRIP">lakshmiDRIP</a></p>
      <p>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></p>
    </footer>
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->
    
  </body>
</html>
